\documentclass[a4paper,11pt]{article}
\include{macros}

% \setcounter{page}{1}

\renewcommand{\baselinestretch}{1.02} 
\begin{document}


\begin{center} 
% {\large Vetenskapsrådet: Distinguished professor grant within natural and engineering sciences 2024} \vspace{2.5mm}\\
{\Large Research plan} \vspace{3mm}\\
{\Large\bf {\proposaltitle} {\sc (}{\acronymtitle}{\sc )}}  \vspace{3mm} \\
{\Large Aristides Gionis} 
\end{center}

\instructions{
The research plan shall be forward-looking and consist of a brief but complete description of the research task. It may cover a maximum of 10 page-numbered A4 pages in Arial, font size 11, single line spacing and 2.5 cm margins, including references and any images.\\
The research plan must include the following headings and information, listed in the following order:
}

\section{Purpose and aims {\color{orange}[$\approx$1.5 pages]} {\color{teal}(Aris)}}

\instructions{
State the overall purpose and specific aims of the research project.
}



\section{State of the art {\color{orange}[$\approx$1 page]} {\color{teal}(Sebastian)}}

\instructions{
Summarize briefly the current research frontier within the field or area covered by the project. State key references.
}

\section{Significance and scientific novelty  {\color{orange}[$\approx$0.5 page]} {\color{teal}(Aris)}}

\instructions{
Describe briefly how the project relates to previous research within the area, and the impact the project may have in the short and long term. Describe also how the project moves forward or innovates the current research frontier.
}

\section{Preliminary and previous results  {\color{orange}[$\approx$0.5 page]} {\color{teal}(Aris)}}

\instructions{
Describe briefly your own previous research and pilot studies within the research area that make it probable that the project will be feasible. If no preliminary results exist, please state this too. State also whether the project contributes further to research and scientific results from a grant awarded previously by the Swedish Research Council.
}

\section{Project description {\color{orange}[$\approx$5 pages]}}

\instructions{
Describe the project design under the following headings:
}

\subsection{Theory and methods {\color{orange}[$\approx$3-4 pages]} {\color{teal}(Sebastian)}}

\instructions{
Describe the underlying theory and the methods to be applied in order to reach the project goal.
}

The project is structured along three {\em research themes}:

\begin{description}
\setlength{\itemsep}{-2pt}
\item[\rto.~\newmodels\,:] 

\item[\rtw.~\clusterings\,:] 

\item[\rth.~\covariates\,:]
\end{description}

When considering different approaches for explainable clustering we distinguish between 
two different computational paradigms. 
\begin{description}
\setlength{\itemsep}{-2pt}
\item[\posthoc\,:]
In the first paradigm, we assume that a clustering of the data is provided 
from a \emph{black-box clustering method} and the problem objective is to design 
a \emph{post-hoc} explanation of the input clustering.
This task is similar to \emph{interpretable machine learning}~\cite{XXX}, 
where one asks to develop post-hoc interpretable justifications for 
\emph{black-box classification models}, such as neural networks. 
The difference is \ldots 
\item[\joint\,:]
In the second paradigm, one is given as input a set of data points, 
and the goal is to find an optimal clustering of the data
from a family of explainable clustering models.
That is, one needs to \emph{cluster the data} and \emph{select the explainable clustering model}
in a \emph{joint fashion}.
In the general case, the clustering cost incurred by an explainable model 
will be larger than the cost incurred by an optimal (but non-explainable) model, 
so our goal will be to bound the cost of the explainable model with respect to the optimal cost.
\end{description}

Next we discuss in more detail the three research themes of \acronym.
The two paradigms, \posthoc\ and \joint, are present in all three of our research themes.
When discussing different explainable-clustering approaches 
we specify the paradigm for a specific approach.

\subsection*{Research theme 1 (\rto): \newmodels\ {\color{orange}[$\approx$1 page]} {\color{teal}(Sebastian)}}

Given a clustering produced by any black-box clustering method, e.g., $k$-means,
provide explanations of the clustering using models that go beyond axis-aligned decision trees.
Such models include 
(i) non-axis aligned decision trees;
(ii) decision rules or decision lists;
(iii) ??
Here we can also include work on explaining clusterings using feature importance. 

Existing methods that explain clustering results with axis-aligned decision trees
provide quality guarantees.
Ensuring that our methods, will provide quality guarantees for the novel models
we will introduce is a major challenge for this research theme.

\subsection*{Research theme 2 (\rtw): \clusterings\ {\color{orange}[$\approx$1 page]} {\color{teal}(Sebastian)}}

Here we will focus on developing methods providing explanations for clusterings 
that go beyond centroid-based approaches like $k$-means or $k$-median.
In particular we will consider the following clustering approaches.
\begin{itemize}
\setlength{\itemsep}{-2pt}
\item kernel-based clustering
\item density-based clustering; what would be a good model for this case?
\item subspace clustering \hfill\ag{does this make sense?}
\item diversity-aware (or fair) clustering \hfill\ag{does this make sense?}
\item what if want the explanation be fair, instead of the clustering?
\item clusterings with embeddings
\end{itemize}

There is strong interaction between \rto and \rtw, 
due to the fact that providing explanations for clusterings that go beyond centroid-based methods
will require working with novel models.

\subsection*{Research theme 3 (\rth): \covariates\ {\color{orange}[$\approx$1 page]} {\color{teal}(Aris)}}

In many application scenarios data can be represented in different ways: 
Most often, data can be represented in a vector space
in which appropriate distance functions, or similarity functions, are considered.
Such a vector space can be defined using directly data features, 
or it can be learned using representation-learning techniques~\cite{hamilton2017representation,wang2020survey}.
Second, data points are associated with covariates, 
which are discrete (categorical) attributes, 
representing certain aspects of the data. 
Such covariates can be labels, tags, or other related information.
Given the discrete nature of covariates it is typically not easy (or meaningful)
to define distance functions based on them, 
although sometimes coarse-grained distance functions can be specified.

For an example illustrating the setting described above, 
consider a collection of news articles. 
Each news article can be represented by a vector in a high-dimensional space, 
e.g., using bag-of-words, \tfidf-type weighting, or deep-learning embedding schemes. 
Furthermore, for each news article we can associate a small 
set of tags, or labels, summarizing the topic of the article, 
e.g., an article reporting on climate change could be labeled by
`\texttt{\small ClimateCrisis}' and `\texttt{\small ExtremeWeather}.'
We refer to these labels as covariate~attributes.

When considering the problem of clustering a dataset in which the data points are 
represented both in vector space and with covariate attributes, 
it is immediate clear how to leverage the vectorial information
using a standard clustering method, such as $k$-means or spectral clustering. 
One of the other hand, it is not obvious how to use effectively the 
covariate attributes in order to improve the clustering results. 

In this research theme we propose finding high-quality clusterings of the data
while using the covariate attributes for explaining the resulting clusterings. 
In particular, we aim to develop novel clustering methods
that achieve low-cost solutions with respect to the vector-representation of the data points, 
while at the same time achieve high expressivity and high specificity of the clusterings
using the covariate attributes. 

To be more concrete, as one possible problem formulation that we will explore, 
let us consider a set of $n$ data points $\dataset=\{\vecx_1,\ldots,\vecx_n\}$
and a set of covariate attributes {\labelset} representing labels for the data points. 
Each data point $\vecx_i$ is associated with a set of labels $\labels_i\subseteq\labelset$. 
A set of labels $\labels=\{\alabel_1,\ldots,\alabel_k\}\subseteq\labelset$, 
henceforth referred to as \emph{descriptor set}, 
\emph{induces} a subset of the data points $\dataset(\labels)\subseteq\dataset$
via a \emph{logic grammar}, such as, for example, 
$\dataset(\labels)$ consists of the data points in \dataset that 
are associated with at least $s$ labels contained in \labels.
For the set of points $\dataset(\labels)$ induced by \labels 
we can then define its \emph{clustering cost} $d(\dataset(\labels))$, 
using the geometry of the points in the set, 
e.g., the diameter of the set, or the sum of distances of all points to the median of the set.
The problem of explainable clustering with covariate attributes that we will study is the following: 
find a collection of label sets $\labels_1,\ldots,\labels_t$, 
so that the induced clusters $\dataset(\labels_1),\ldots,\dataset(\labels_t)$
cover the whole dataset \dataset, 
and some aggregate function on the cost of the clusters is minimized. 
Natural choices for the total clustering cost are
$d_{+}(\labels_1,\ldots,\labels_t) = \sum_{j} d(\dataset(\labels_j))$ and 
$d_{m}(\labels_1,\ldots,\labels_t) = \max_{j}\! \left\{ d(\dataset(\labels_j)) \right\}$, 
that is, we will aim to minimize the total cost, or worst-case cost, respectively, 
among all clusters. 

A few observations are in order for the problem that we define above.
First we note that the problem belongs in the \joint paradigm, 
that is, we aim to \emph{simultaneously} find a low-cost clustering, 
according to vector representation of the data points,
and an explanation of that clustering using the covariate attributes~(labels).
%
Second, notice that we, in fact, define a very large family of problems, 
depending on the logic grammar used to induce clusters from label sets
and the distance-based function used to define the clustering cost.
Notable logic grammars to consider are the disjunctive and conjunctive grammars 
(i.e., a cluster $\dataset(\labels)$ consists of the points 
that contains at least one, or all, respectively, labels in \labels).
Our goal is to systematically study the computational complexity and 
develop methods with provable guarantees
for many of these possible~formulations.
%
Third, we note that in our discussion above we do not impose any
\emph{disjointedness constraint} with respect to label sets or 
memberships of data points to clusters. 
In fact, such constraints are not necessary as minimizing 
our distance-based objectives has the consequence of \emph{implicitly favoring}
disjoint labels and disjoint clusters.
Nevertheless it would be interesting to study variants
of our problem with explicitly stated disjointedness constraints
and understand, theoretically and empirically, 
the price in the clustering cost due to such constraints.

The covariate-based explainability problem we propose in this theme
has interesting connections with existing work, yet it poses novel research challenges.
The most closely-related work is the \emph{cluster descriptor} problem
proposed by Davidson et al.~\cite{davidson2018cluster} 
and studied in follow-up recent papers~\citep{sambaturu2020efficient}.
The main difference is that those earlier works belong in the \posthoc paradigm, 
that is, the clustering is provided as input. 
Our \joint-type formulation provides a more holistic approach and a
significantly better way of leveraging the covariate attributes into the explanation of clustering. 
It also poses significantly different computational challenges
and the opportunity to exploit the geometric structure for solving the problem.

Depending on the progress on this topic, further extensions of the problem can be considered. 
Those include allowing for outliers that can help reducing significantly the clustering cost.
The benefit of this idea is that covariate attributes can be used in the same manner
to also explain the outliers, as the clusters.
Additionally, we can use the same framework analyzing networks and finding 
explainable communities in networks.
The PI has relevant experience of developing methods for finding labeled-induced
(and thus, explainable) densest subgraphs in networks~\cite{galbrun2014overlapping,galbrun2016top}.

\subsection{Time plan and implementation {\color{orange}[$\approx$0.75-1 page]} {\color{teal}(Aris)}}

\instructions{
Describe summarily the time plan for the project during the grant period, and how the project will be implemented. Describe also any crucial risks or obstacles that may impact on the implementation, and your plan for managing these.
}

\subsection{Project organization {\color{orange}[$\approx$0.5 page]} {\color{teal}(Aris)}}

\instructions{
Clarify how you and any participating researchers will contribute to the implementation of the project. Explain in particular how the time allocated by you (that is, your activity level) as project leader is suitable for the task, including the relationship with your other research undertakings. Describe and explain the competences and roles of the participating researchers in the project, and also other key persons (including any doctoral students) who are important for the implementation of the project.
}

\section{Equipment {\color{orange}[$\approx$0.2 page]} {\color{teal}(Aris)}}

\instructions{
Describe the basic equipment you and your team have at your disposal for the project.
}

\section{Need for research infrastructure {\color{orange}[$\approx$0.2 page]} {\color{teal}(Aris)}}

\instructions{
Specify the project’s need for international and national research infrastructure. If you choose to use other infrastructure than those supported by the Swedish Research Council External link.and that are thereby open to all, you must justify this (also applies to local research infrastructure).
}

The project is mainly of theoretical nature and will not require extensive computing infrastructure. 
Commodity laptops will be provided to all team members. 
For implementing and evaluating our methods we will use the available 
KTH computing facilities
and the National Academic Infrastructure for Supercomputing in Sweden (NAISS).

\section{International and national collaboration {\color{orange}[$\approx$0.2 page]} {\color{teal}(Aris)}}

\instructions{
Describe your own and the team’s collaboration with foreign and Swedish researchers and research teams. State whether you contribute to or refer to international collaboration in your research.
}

The PI has an extensive international collaboration network. 
Recent and on-going collaborations include
prof.\ De Bie in Ghent University, 
prof.\ Terzi in Boston University,
prof.\ Mannila in Aalto University, and 
Dr.\ Bonchi in Centai Labs.
In spring 2024 the PI will spent one month as a visiting professor 
in Sapienza University of Rome, hosted by prof.\ Leonardi.
In the near future the PI will apply for a sabbatical in Stanford University, 
planning to visit prof.\ Ugander. 
We will seek to strengthen and further expand this collaboration network.
We will encourage the research team to be actively involved in national and international collaborations
and make research visits and internships in other institutes.

\section{Independent line of research {\color{orange}[$\approx$0.2 page]} {\color{teal}(Aris)}}

\instructions{
If you are working or will be working in a larger group, please clarify how your project relates to the other projects in the group. If you are (continuing) working in the same team as your doctoral or postdoc supervisor, or if you are continuing a project that wholly or partly started during your doctoral or postdoc studies, you must also describe the relationship between your project and the research of your former supervisor.
}


{\small
\setlength{\bibsep}{0pt}
\bibliographystyle{abbrv}
\bibliography{references}
}

% \newpage
% \input{rebound}

\end{document}




