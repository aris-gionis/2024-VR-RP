The project contributes to the development of explainable methods for data analysis. The proposed research falls in the broad area of responsble AI. This increasingly growing area is a response to the realization that non-trasparent methods in machine learning pose significant risks to the integrity and accountability of algorithms, and that lack of transparency hinders trust and understanding among users and stakeholders. As a result, designing transparent methods for machine learning is imperative to mitigate these risks, ensuring that algorithms are explainable, interpretable, and accountable. Transparent methods not only promote trust but also empower users to comprehend and challenge model decisions, ultimately fostering a more responsible and ethical deployment of AI technology.

To the best of our understanding, the proposed research does not pose significant risks, nor it is clear to us how the foreseen methods can be misused by malicious agents. None the less, during the course of the project we will constantly evaluate ethical considerations related to our research and will discuss possible risks and mitigation strategies with the team members. We will also promote the culture of discussing ethical considerations in the reflection section of our research papers.